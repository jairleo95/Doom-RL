{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ynb-laSwmpac"
   },
   "source": [
    "# Loading and visualizing results ([open in colab](https://colab.research.google.com/github/openai/baselines/blob/master/docs/viz/viz.ipynb))\n",
    "In order to compare performance of algorithms, we often would like to visualize learning curves (reward as a function of time steps), or some other auxiliary information about learning aggregated into a plot. Baselines repo provides tools for doing so in several different ways, depending on the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yreoV7OClzYG"
   },
   "source": [
    "## Preliminaries / TensorBoard\n",
    "First, let us install baselines repo from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4Aul2Qujlg9"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/baselines > ~/pip_install_baselines.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1n7XAyVWniRp"
   },
   "source": [
    "For all algorithms in baselines summary data is saved into a folder defined by logger. By default, a folder $TMPDIR/openai-<date>-<time> is used; you can see the location of logger directory at the beginning of the training in the message like this:\n",
    "\n",
    "Logging to /var/folders/mq/tgrn7bs17s1fnhlwt314b2fm0000gn/T/openai-2018-10-29-15-03-13-537078\n",
    "The location can be changed by changing OPENAI_LOGDIR environment variable. For instance, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32433,
     "status": "ok",
     "timestamp": 1541626389411,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "xzqFBYiZjtUr",
    "outputId": "92dc8be5-c18c-4399-b2d0-0f444b321a13"
   },
   "outputs": [],
   "source": [
    "!OPENAI_LOGDIR=$HOME/logs/cartpole-ppo OPENAI_LOG_FORMAT=csv python -m baselines.run --alg=ppo2 --env=CartPole-v0 --num_timesteps=30000 --nsteps=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYwTBFMCn95w"
   },
   "source": [
    "Notice also the usage of `OPENAI_LOG_FORMAT` environment variable - this allows us to suppress printing to stdout. \n",
    "Permissible values for `OPENAI_LOG_FORMAT` environment variables are `stdout`, `log`, `csv`, and `tensorboard` (multiple values can be comma-separated). \n",
    "The latter one (`tensorboard`) dumps values in tensorboard format, which allows for their viewing in [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard). TensorBoard provides nice visualization and in many cases is the easiest way to look at the summary of the results. However, if tensorboard visualization is not sufficient, read on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcWDWCfIojHy"
   },
   "source": [
    "## Loading results and plotting using matplotlib\n",
    "BÐ°selines provides helper functions to load the summaries of the results as pandas dataframes. \n",
    "For instance, the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1541626398698,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "cDdZjFR2kFG2",
    "outputId": "09d91a7a-f851-459b-903a-f8c1d32ccb8e"
   },
   "outputs": [],
   "source": [
    "from baselines.common import plot_util as pu\n",
    "results = pu.load_results('~/logs/cartpole-ppo') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sj3jfhbBpGPq"
   },
   "source": [
    "will search for all folders with baselines-compatible results in ~/logs/cartpole-ppo and subfolders and return a list of `Result` objects. Each `Result` object is a named tuple with the following fields:\n",
    "\n",
    "  * dirname: str - name of the folder from which data was loaded\n",
    "  \n",
    "  * metadata: dict) - dictionary with various metadata (read from metadata.json file)\n",
    "\n",
    "  * progress: pandas.DataFrame - tabular data saved by logger as a pandas dataframe. Available if csv is in logger formats.\n",
    "\n",
    "  * monitor: pandas.DataFrame - raw episode data (length, episode reward, timestamp). Available if environment wrapped with Monitor wrapper\n",
    "  \n",
    "Thus, a learning curve from a single run can be plotted as follows (note the cumulative sum trick to get convert lengths of the episodes into number of time steps taken so far)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1541626401733,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "jEBxUzvVsNbP",
    "outputId": "7b7016a5-6f94-4384-821d-a9e197211315"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "r = results[0]\n",
    "plt.plot(np.cumsum(r.monitor.l), r.monitor.r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLGJgLFjqLDB"
   },
   "source": [
    "The raw learning curve from a single run can be very noisy. To smoothen it and analyze if any learning actually takes place, we can use `plot_util.smooth()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1541626405684,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "Rz4vAnURuURX",
    "outputId": "f5e38cd7-c63c-4b9c-aaa0-b24592b636ba"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_e-NRHW8qoMF"
   },
   "source": [
    "Similar curve can be obtained by using logger summaries (instead of raw episode data in monitor.csv):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1541626409332,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "E2PawoKEua1N",
    "outputId": "02c4b58e-b665-4534-d02c-24c5862e473f"
   },
   "outputs": [],
   "source": [
    "plt.plot(r.progress.total_timesteps, r.progress.eprewmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iI5DRKArEVl"
   },
   "source": [
    "Note, however, that raw episode data is stored by the Monitor wrapper, and hence looks similar for all algorithms, whereas progress data is handled by the algorithm itself, and hence can vary (column names, type of data available) between algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETICR8zsrKg2"
   },
   "source": [
    "## Plotting: many curves\n",
    "While the loading and plotting functions described above in principle give you access to any slice of the training summaries, sometimes it is necessary to plot and compare many training runs (multiple algorithms, multiple seeds for random number generator), and usage of the functions above can get tedious and messy. For that case, `baselines.common.plot_util` provides convenience function plot_results that handles multiple `Result` objects that need to be routed in multiple plots. Consider the following bash snippet that runs ppo2 with cartpole with 6 different seeds for 30k time steps, first with rollout batch size 32, and then with batch size 128 (note that the next cell will take a little while to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470993,
     "status": "ok",
     "timestamp": 1541626885128,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "OLEYIE95ue2e",
    "outputId": "d1f2760b-1433-4b73-c5ce-ceace66e07cc"
   },
   "outputs": [],
   "source": [
    "!for seed in $(seq 0 5); do OPENAI_LOG_FORMAT=csv OPENAI_LOGDIR=$HOME/logs/cartpole-ppo-hp/b32-$seed python -m baselines.run --alg=ppo2 --env=CartPole-v0 --num_timesteps=3e4 --seed=$seed --nsteps=32; done\n",
    "!for seed in $(seq 0 5); do OPENAI_LOG_FORMAT=csv OPENAI_LOGDIR=$HOME/logs/cartpole-ppo-hp/b128-$seed python -m baselines.run --alg=ppo2 --env=CartPole-v0 --num_timesteps=3e4 --seed=$seed --nsteps=128; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzG8DDNwrwbG"
   },
   "source": [
    "The results of 12 runs from the cell above can be loaded just as before, via (we discard first result that is actually from the very first run in the previous section):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1541629440197,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "cNKemLHPv03E",
    "outputId": "8ff4813e-23f3-4696-a531-6ef3bd12c569"
   },
   "outputs": [],
   "source": [
    "results = pu.load_results('~/logs/cartpole-ppo-hp'); print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xy388w_tssIL"
   },
   "source": [
    "But how do we plot all 12 of them in a sensible manner? `baselines.common.plot_util` module provides plot_results function to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1541629448579,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "1yemaAkKweB2",
    "outputId": "612d1da5-e2a1-4836-b223-aebfaa3feac6"
   },
   "outputs": [],
   "source": [
    "pu.plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUNu5fEfsvot"
   },
   "source": [
    "The results are split into two groups based on batch size and are plotted on a separate graph. More specifically, by default plot_results considers digits after dash at the end of the directory name to be seed id and groups the runs that differ only by those together.\n",
    "\n",
    "Showing all seeds on the same plot may be somewhat hard to comprehend and analyse. We can instead average over all seeds via the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1541629456405,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "7d_aeRYXacFP",
    "outputId": "22554c64-b5a5-4892-81d0-8a7d0d3569a4"
   },
   "outputs": [],
   "source": [
    "pu.plot_results(results, average_group=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iA89jxdgtElg"
   },
   "source": [
    "The lighter shade shows the standard deviation of data, and darker shade - error in estimate of the mean (that is, standard deviation divided by square root of number of seeds). Note that averaging over seeds requires resampling to a common grid, which, in turn, requires smoothing (using language of signal processing, we need to do low-pass filtering before resampling to avoid aliasing effects). You can change the amount of smoothing by adjusting `resample` and `smooth_step` arguments to achieve desired smoothing effect See the docstring of plot_util function for more info.\n",
    "\n",
    "To plot both groups on the same graph, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1541629463814,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "_5IMVF3EGBMD",
    "outputId": "b29e81b6-8a57-4007-fe31-86652b7ee1e5"
   },
   "outputs": [],
   "source": [
    "pu.plot_results(results, average_group=True, split_fn=lambda _: '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABZmMmCmtQ1X"
   },
   "source": [
    "Option `split_fn=labmda _:''` effectively disables splitting, so that all curves end up on the same panel.\n",
    "\n",
    "Now, with many groups the overlapping shaded regions may start looking messy. We can disable either light shaded region (corresponding to standard deviation of the curves in the group) or darker shaded region (corresponding to the error in mean estimate) by using `shaded_std=False` or `shaded_err=False` options respectively. For instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1541629471846,
     "user": {
      "displayName": "Peter Zhokhov",
      "photoUrl": "",
      "userId": "10254602425711636265"
     },
     "user_tz": 480
    },
    "id": "x4rVG6RGI31B",
    "outputId": "a036e51d-b6c6-4855-ce5a-a42c149a59ee"
   },
   "outputs": [],
   "source": [
    "pu.plot_results(results, average_group=True, split_fn=lambda _: '', shaded_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMA86VtfI8d5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "baselines_viz.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
